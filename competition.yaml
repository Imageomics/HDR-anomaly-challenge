# The Yaml file contains the main parameters describing the challenge.
# You can learn more about the possible settings here: # More options here: https://github.com/codalab/codabench/wiki/Yaml-Structure
# Modified from sample competition file downloaded from https://github.com/codalab/competition-examples/tree/master/codabench/iris 

# Main settings
version: 2 # this means that it is a Codabench bundle
title: Butterfly Hybrid Detection
description: This challenge is to detect hybrids among two species of butterflies and their subspecies.
image: Imageomics_logo_butterfly.png
registration_auto_approve: True  # do not require approval from admin to join the comp
docker_image: 'codalab/codalab-legacy:py37' # This likely needs updating

# Documentation web pages
terms: pages/terms.md
pages:
  - title: Overview
    file: pages/overview.md
  - title: Data
    file: pages/data.md
  - title: Evaluation
    file: pages/evaluation.md
  - title: Terms
    file: pages/terms.md
  - title: Starting Kit and Sample Submission
    file: pages/starting_kit.md

# Definition of the tasks: Species A dev + final and Mimic dev + final
tasks:
- index: 0
  name: Species A Development Task
  description: 'Development phase: create models and submit results on validation
    and/or test data for Species A hybrid detection; feedback provided on the validation set only.'
  is_public: false
  input_data: input_data_species_A
  reference_data: reference_data/valid_A
  scoring_program: scoring_program_A  # Only required part along with name and description
  ingestion_program: ingestion_program
  - index: 1
  name: Mimic Development Task
  description: 'Development phase: create models and submit results on validation
    and/or test data for Mimic hybrid detection; feedback provided on the validation set only.'
  is_public: false
  input_data: input_data_mimic
  reference_data: reference_data/valid_mimic
  scoring_program: scoring_program_mimic
  ingestion_program: ingestion_program
  - index: 2
  name: Species A Final Task
  description: 'Final phase: submissions from the previous phase are automatically
    cloned and used to compute the final score on Species A hybrid detection. 
    The results on the test set will be revealed when the organizers make them available.'
  is_public: false
  input_data: input_data_species_A
  reference_data: reference_data/test_A
  scoring_program: scoring_program_A
  ingestion_program: ingestion_program
- index: 3
  name: Final Task Mimic
  description: 'Final phase: submissions from the previous phase are automatically
    cloned and used to compute the final score on Mimic hybrid detection. 
    The results on the test set will be revealed when the organizers make them available.'
  is_public: false
  input_data: input_data_mimic
  reference_data: reference_data/test_mimic
  scoring_program: scoring_program_mimic
  ingestion_program: ingestion_program
solutions: []

# There are 2 phases: development phase and final phase
# Each one is linked to the associated Species A and Mimic tasks
phases:
- index: 0
  name: Development
  description: 'Development phase: create models and submit results on validation
    and/or test data for hybrid detection; feedback provided on the validation set only.'
  start: 6-15-2024 # Month-Day-Year
  end: 9-12-2024
  max_submissions_per_day: # limits are extra
  max_submissions: 
  execution_time_limit: 
  tasks:
  - 0
  - 1
  solutions: []
- index: 1
  name: Final
  description: 'Final phase: submissions from the previous phase are automatically
    cloned and used to compute the final score. The results on the test set will be
    revealed when the organizers make them available.'
  start: 9-12-2024 # just last day?
  end: 9-12-2024
  max_submissions_per_day: 0
  max_submissions: 1
  execution_time_limit: 
  tasks:
  - 2
  - 3
  solutions: []

# Leaderboard
# Precision doesn't show up in the Iris sample, but it is on the UI
# UI also has Submission Rule option (Force Last?)
leaderboards:
- index: 0
  title: Detection Rate
  key: detection-results
  columns:
  - title: Major Hybrids
    key: A_score_major
    index: 0
    sorting: desc
    computation: null
    computation_indexes: null
  - title: Minor Hybrids
    key: A_score_minor
    index: 1
    sorting: desc
    computation: null
    computation_indexes: null
  - title: AUC Species A Hybrids
    key: A_AUC
    index: 2
    sorting: desc
    computation: null
    computation_indexes: null
  - title: Mimic Hybrids
    key: mimic_score
    index: 3
    sorting: desc
    computation: null
    computation_indexes: null
  - title: AUC Mimic Hybrids
    key: mimic_AUC
    index: 4
    sorting: desc
    computation: null
    computation_indexes: null
  - title: Challenge Score  # Removed Duration
    key: challenge_score
    index: 5
    sorting: desc
    computation: min   # Could we make our own from the scoring program or must it consider the other columns somehow?
    computation_indexes: # Take scores on Species A and Mimic hybrid detection?
      - 0
      - 1
      - 3   
